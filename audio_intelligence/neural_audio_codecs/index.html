
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
        <link rel="canonical" href="http://mohitmayank.com/a_lazy_data_science_guide/audio_intelligence/neural_audio_codecs/">
      
      <link rel="icon" href="../../imgs/logo.png">
      <meta name="generator" content="mkdocs-1.3.0, mkdocs-material-8.3.4">
    
    
      
        <title>Neural Audio Codecs - A Lazy Data Science Guide</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.4a0965b7.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.cbb835fc.min.css">
        
      
      
    
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("../..",location),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      
  


  
  


  <script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-2DVXT9L5D4"),document.addEventListener("DOMContentLoaded",function(){document.forms.search&&document.forms.search.query.addEventListener("blur",function(){this.value&&gtag("event","search",{search_term:this.value})}),"undefined"!=typeof location$&&location$.subscribe(function(e){gtag("config","G-2DVXT9L5D4",{page_path:e.pathname})})})</script>
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-2DVXT9L5D4"></script>


    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="" data-md-color-accent="">
  
    
    
      <script>var palette=__md_get("__palette");if(palette&&"object"==typeof palette.color)for(var key of Object.keys(palette.color))document.body.setAttribute("data-md-color-"+key,palette.color[key])</script>
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#neural-audio-codecs" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
        <aside class="md-banner">
          <div class="md-banner__inner md-grid md-typeset">
            
  Don't forget to give us a star on
  <a rel="me" href="https://github.com/imohitmayank/a_lazy_data_science_guide">
    <span class="twemoji github">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.1.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>
    </span>
    <strong>Github</strong>
  </a>
  . For updates follow <strong>Mohit Mayank</strong> on 
  <a href="https://www.linkedin.com/in/imohitmayank/">
    <span class="twemoji linkedin">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.1.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"/></svg>
    </span>
    <strong>LinkedIn</strong>
  </a>
  and
  <a href="https://twitter.com/imohitmayank">
    <span class="twemoji twitter">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.1.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"/></svg>
    </span>
    <strong>Twitter</strong>
  </a>

          </div>
        </aside>
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="A Lazy Data Science Guide" class="md-header__button md-logo" aria-label="A Lazy Data Science Guide" data-md-component="logo">
      
  <img src="../../imgs/logo.png" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            A Lazy Data Science Guide
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Neural Audio Codecs
            
          </span>
        </div>
      </div>
    </div>
    
      <form class="md-header__option" data-md-component="palette">
        
          
          
          <input class="md-option" data-md-color-media="" data-md-color-scheme="default" data-md-color-primary="" data-md-color-accent=""  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_1">
          
            <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_2" hidden>
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 6H7c-3.31 0-6 2.69-6 6s2.69 6 6 6h10c3.31 0 6-2.69 6-6s-2.69-6-6-6zm0 10H7c-2.21 0-4-1.79-4-4s1.79-4 4-4h10c2.21 0 4 1.79 4 4s-1.79 4-4 4zM7 9c-1.66 0-3 1.34-3 3s1.34 3 3 3 3-1.34 3-3-1.34-3-3-3z"/></svg>
            </label>
          
        
          
          
          <input class="md-option" data-md-color-media="" data-md-color-scheme="slate" data-md-color-primary="red" data-md-color-accent=""  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_2">
          
            <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_1" hidden>
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 7H7a5 5 0 0 0-5 5 5 5 0 0 0 5 5h10a5 5 0 0 0 5-5 5 5 0 0 0-5-5m0 8a3 3 0 0 1-3-3 3 3 0 0 1 3-3 3 3 0 0 1 3 3 3 3 0 0 1-3 3Z"/></svg>
            </label>
          
        
      </form>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" aria-label="Clear" tabindex="-1">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/imohitmayank/a_lazy_data_science_guide" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.1.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
            
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-tabs__inner md-grid">
    <ul class="md-tabs__list">
      
        
  
  


  
  
  
    <li class="md-tabs__item">
      <a href="../.." class="md-tabs__link">
        Introduction
      </a>
    </li>
  

      
        
  
  


  
  
  
    <li class="md-tabs__item">
      <a href="../../natural_language_processing/interview_questions/" class="md-tabs__link">
        Natural Language Processing
      </a>
    </li>
  

      
        
  
  
    
  


  
  
  
    <li class="md-tabs__item">
      <a href="../interview_questions/" class="md-tabs__link md-tabs__link--active">
        Audio Intelligence
      </a>
    </li>
  

      
        
  
  


  
  
  
    <li class="md-tabs__item">
      <a href="../../network_science/introduction/" class="md-tabs__link">
        Network Science
      </a>
    </li>
  

      
        
  
  


  
  
  
    <li class="md-tabs__item">
      <a href="../../data_science_tools/introduction/" class="md-tabs__link">
        Data Science Tools
      </a>
    </li>
  

      
        
  
  


  
  
  
    <li class="md-tabs__item">
      <a href="../../machine_learning/introduction/" class="md-tabs__link">
        Machine Learning
      </a>
    </li>
  

      
        
  
  


  
  
  
    <li class="md-tabs__item">
      <a href="../../reinforcement_learning/introduction/" class="md-tabs__link">
        Reinforcement Learning
      </a>
    </li>
  

      
    </ul>
  </div>
</nav>
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="A Lazy Data Science Guide" class="md-nav__button md-logo" aria-label="A Lazy Data Science Guide" data-md-component="logo">
      
  <img src="../../imgs/logo.png" alt="logo">

    </a>
    A Lazy Data Science Guide
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/imohitmayank/a_lazy_data_science_guide" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.1.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_1" type="checkbox" id="__nav_1" >
      
      
      
      
        <label class="md-nav__link" for="__nav_1">
          Introduction
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Introduction" data-md-level="1">
        <label class="md-nav__title" for="__nav_1">
          <span class="md-nav__icon md-icon"></span>
          Introduction
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        Hello
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../introduction/getting_started/" class="md-nav__link">
        Getting started with Data Science
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_2" type="checkbox" id="__nav_2" >
      
      
      
      
        <label class="md-nav__link" for="__nav_2">
          Natural Language Processing
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Natural Language Processing" data-md-level="1">
        <label class="md-nav__title" for="__nav_2">
          <span class="md-nav__icon md-icon"></span>
          Natural Language Processing
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../natural_language_processing/interview_questions/" class="md-nav__link">
        Interview Questions
      </a>
    </li>
  

            
          
            
              
  
  
  
    
      
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_2_2" type="checkbox" id="__nav_2_2" >
      
      
      
      
        <label class="md-nav__link" for="__nav_2_2">
          Architectures/Models
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Architectures/Models" data-md-level="2">
        <label class="md-nav__title" for="__nav_2_2">
          <span class="md-nav__icon md-icon"></span>
          Architectures/Models
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../natural_language_processing/word2vec/" class="md-nav__link">
        Word2Vec
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../natural_language_processing/lstm_gru_rnn/" class="md-nav__link">
        LSTM, GRU & RNN
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../natural_language_processing/transformer/" class="md-nav__link">
        Transformers
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../natural_language_processing/BERT/" class="md-nav__link">
        BERT
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../natural_language_processing/GPTs/" class="md-nav__link">
        GPTs
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../natural_language_processing/minilm/" class="md-nav__link">
        MiniLM
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../natural_language_processing/T5/" class="md-nav__link">
        T5
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../natural_language_processing/FlanModels/" class="md-nav__link">
        FlanModels
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../natural_language_processing/llama/" class="md-nav__link">
        LLaMA
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../natural_language_processing/mamba/" class="md-nav__link">
        Mamba
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../natural_language_processing/deepseek/" class="md-nav__link">
        DeepSeek R1
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
      
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_2_3" type="checkbox" id="__nav_2_3" >
      
      
      
      
        <label class="md-nav__link" for="__nav_2_3">
          Large Language Models
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Large Language Models" data-md-level="2">
        <label class="md-nav__title" for="__nav_2_3">
          <span class="md-nav__icon md-icon"></span>
          Large Language Models
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../natural_language_processing/training_llm/" class="md-nav__link">
        Training LLMs
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../natural_language_processing/prompt_engineering/" class="md-nav__link">
        Prompt Engineering
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../natural_language_processing/explainable_ai_llm/" class="md-nav__link">
        Explainable AI: LanguageÂ Models
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../natural_language_processing/streaming_chatgpt_gen/" class="md-nav__link">
        Streaming ChatGPT Generations
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../natural_language_processing/making_llm_multilingual/" class="md-nav__link">
        Making LLM Multi-lingual
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
      
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_2_4" type="checkbox" id="__nav_2_4" >
      
      
      
      
        <label class="md-nav__link" for="__nav_2_4">
          Tasks
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Tasks" data-md-level="2">
        <label class="md-nav__title" for="__nav_2_4">
          <span class="md-nav__icon md-icon"></span>
          Tasks
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../natural_language_processing/paraphraser/" class="md-nav__link">
        Paraphraser
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../natural_language_processing/text_similarity/" class="md-nav__link">
        Text similarity
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../natural_language_processing/text_generation/" class="md-nav__link">
        Text generation
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../natural_language_processing/relation_extraction/" class="md-nav__link">
        Relation extraction
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../natural_language_processing/qa/" class="md-nav__link">
        Question Answering
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../natural_language_processing/data_to_text_generation/" class="md-nav__link">
        Data-to-Text Generation
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../natural_language_processing/named_entity_recognition/" class="md-nav__link">
        Named Entity Recognition
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../natural_language_processing/nlq/" class="md-nav__link">
        Natural Language Querying
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
    
  
  
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_3" type="checkbox" id="__nav_3" checked>
      
      
      
      
        <label class="md-nav__link" for="__nav_3">
          Audio Intelligence
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Audio Intelligence" data-md-level="1">
        <label class="md-nav__title" for="__nav_3">
          <span class="md-nav__icon md-icon"></span>
          Audio Intelligence
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../interview_questions/" class="md-nav__link">
        Interview Questions
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../audio_snippets/" class="md-nav__link">
        Code Snippets
      </a>
    </li>
  

            
          
            
              
  
  
  
    
      
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_3_3" type="checkbox" id="__nav_3_3" >
      
      
      
      
        <label class="md-nav__link" for="__nav_3_3">
          Speech-to-Text
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Speech-to-Text" data-md-level="2">
        <label class="md-nav__title" for="__nav_3_3">
          <span class="md-nav__icon md-icon"></span>
          Speech-to-Text
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../stt/" class="md-nav__link">
        STT Introduction
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../wav2vec2/" class="md-nav__link">
        Wav2Vec2 Model
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../whisper/" class="md-nav__link">
        Whisper Model
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../connectionist_temporal_classification/" class="md-nav__link">
        Connectionist Temporal Classification
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
    
  
  
    
      
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_3_4" type="checkbox" id="__nav_3_4" checked>
      
      
      
      
        <label class="md-nav__link" for="__nav_3_4">
          Text-to-Speech
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Text-to-Speech" data-md-level="2">
        <label class="md-nav__title" for="__nav_3_4">
          <span class="md-nav__icon md-icon"></span>
          Text-to-Speech
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../tts/" class="md-nav__link">
        TTS Introduction
      </a>
    </li>
  

            
          
            
              
  
  
    
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" data-md-toggle="toc" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          Neural Audio Codecs
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        Neural Audio Codecs
      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#introduction" class="md-nav__link">
    Introduction
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#traditional-audio-codecs" class="md-nav__link">
    Traditional Audio Codecs
  </a>
  
    <nav class="md-nav" aria-label="Traditional Audio Codecs">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#waveform-codecs" class="md-nav__link">
    Waveform Codecs
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#parametric-codecs" class="md-nav__link">
    Parametric Codecs
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#neural-audio-codecs_1" class="md-nav__link">
    Neural Audio Codecs
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#soundstream-end-to-end-neural-audio-coding" class="md-nav__link">
    SoundStream: End-to-End Neural Audio Coding
  </a>
  
    <nav class="md-nav" aria-label="SoundStream: End-to-End Neural Audio Coding">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#key-innovations" class="md-nav__link">
    Key Innovations
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#architectural-design" class="md-nav__link">
    Architectural Design
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#training-methodology" class="md-nav__link">
    Training Methodology
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#results" class="md-nav__link">
    Results
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#encodec-high-fidelity-neural-compression" class="md-nav__link">
    EnCodec: High-Fidelity Neural Compression
  </a>
  
    <nav class="md-nav" aria-label="EnCodec: High-Fidelity Neural Compression">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#key-innovations_1" class="md-nav__link">
    Key Innovations
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#results_1" class="md-nav__link">
    Results
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#hilcodec-lightweight-and-efficient-streaming" class="md-nav__link">
    HILCodec: Lightweight and Efficient Streaming
  </a>
  
    <nav class="md-nav" aria-label="HILCodec: Lightweight and Efficient Streaming">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#key-innovations_2" class="md-nav__link">
    Key Innovations
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#results_2" class="md-nav__link">
    Results
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#snac-multi-scale-neural-audio-codec" class="md-nav__link">
    SNAC: Multi-Scale Neural Audio Codec
  </a>
  
    <nav class="md-nav" aria-label="SNAC: Multi-Scale Neural Audio Codec">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#key-innovations_3" class="md-nav__link">
    Key Innovations
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#architectural-design_1" class="md-nav__link">
    Architectural Design
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#results_3" class="md-nav__link">
    Results
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#code" class="md-nav__link">
    Code
  </a>
  
    <nav class="md-nav" aria-label="Code">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#load-the-encodec-model-and-processor" class="md-nav__link">
    Load the EnCodec Model and Processor
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#loading-the-audio" class="md-nav__link">
    Loading the Audio
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#preprocessing-the-audio" class="md-nav__link">
    Preprocessing the Audio
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#encoding-the-audio" class="md-nav__link">
    Encoding the Audio
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#decoding-the-audio" class="md-nav__link">
    Decoding the Audio
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#comparative-analysis" class="md-nav__link">
    Comparative Analysis
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#challenges-and-future-directions" class="md-nav__link">
    Challenges and Future Directions
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#conclusion" class="md-nav__link">
    Conclusion
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#references" class="md-nav__link">
    References
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../training_tts/" class="md-nav__link">
        Training LLM-Based + Neural Codec TTS Models
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
      
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_3_5" type="checkbox" id="__nav_3_5" >
      
      
      
      
        <label class="md-nav__link" for="__nav_3_5">
          Applications
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Applications" data-md-level="2">
        <label class="md-nav__title" for="__nav_3_5">
          <span class="md-nav__icon md-icon"></span>
          Applications
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../voice_activity_detection/" class="md-nav__link">
        Voice Activity Detection
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../speaker_diarization/" class="md-nav__link">
        Speaker Diarization
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4" type="checkbox" id="__nav_4" >
      
      
      
      
        <label class="md-nav__link" for="__nav_4">
          Network Science
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Network Science" data-md-level="1">
        <label class="md-nav__title" for="__nav_4">
          <span class="md-nav__icon md-icon"></span>
          Network Science
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../network_science/introduction/" class="md-nav__link">
        Introduction
      </a>
    </li>
  

            
          
            
              
  
  
  
    
      
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4_2" type="checkbox" id="__nav_4_2" >
      
      
      
      
        <label class="md-nav__link" for="__nav_4_2">
          Graph Neural Networks
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Graph Neural Networks" data-md-level="2">
        <label class="md-nav__title" for="__nav_4_2">
          <span class="md-nav__icon md-icon"></span>
          Graph Neural Networks
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../network_science/gnn_introduction/" class="md-nav__link">
        Introduction
      </a>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4_2_2" type="checkbox" id="__nav_4_2_2" >
      
      
      
      
        <label class="md-nav__link" for="__nav_4_2_2">
          Algorithms
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Algorithms" data-md-level="3">
        <label class="md-nav__title" for="__nav_4_2_2">
          <span class="md-nav__icon md-icon"></span>
          Algorithms
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../network_science/gnn_deepwalk/" class="md-nav__link">
        DeepWalk
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
      
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4_3" type="checkbox" id="__nav_4_3" >
      
      
      
      
        <label class="md-nav__link" for="__nav_4_3">
          Knowledge Graphs
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Knowledge Graphs" data-md-level="2">
        <label class="md-nav__title" for="__nav_4_3">
          <span class="md-nav__icon md-icon"></span>
          Knowledge Graphs
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../network_science/kg_introduction/" class="md-nav__link">
        Introduction
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../network_science/kg_embedding_algorithms/" class="md-nav__link">
        KG Embedding Algorithms
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_5" type="checkbox" id="__nav_5" >
      
      
      
      
        <label class="md-nav__link" for="__nav_5">
          Data Science Tools
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Data Science Tools" data-md-level="1">
        <label class="md-nav__title" for="__nav_5">
          <span class="md-nav__icon md-icon"></span>
          Data Science Tools
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../data_science_tools/introduction/" class="md-nav__link">
        Introduction
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../data_science_tools/python_snippets/" class="md-nav__link">
        Python snippets
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../data_science_tools/linux_snippets/" class="md-nav__link">
        Linux snippets
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../data_science_tools/version_control/" class="md-nav__link">
        Version control
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../data_science_tools/compute_and_ai_services/" class="md-nav__link">
        Compute and AI Services
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../data_science_tools/scraping_websites/" class="md-nav__link">
        Scraping Websites
      </a>
    </li>
  

            
          
            
              
  
  
  
    
      
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_5_7" type="checkbox" id="__nav_5_7" >
      
      
      
      
        <label class="md-nav__link" for="__nav_5_7">
          Database
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Database" data-md-level="2">
        <label class="md-nav__title" for="__nav_5_7">
          <span class="md-nav__icon md-icon"></span>
          Database
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../data_science_tools/databases_introduction/" class="md-nav__link">
        Introduction
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../data_science_tools/database_postgresql/" class="md-nav__link">
        PostgreSQL
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
      
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_5_8" type="checkbox" id="__nav_5_8" >
      
      
      
      
        <label class="md-nav__link" for="__nav_5_8">
          Good Practices
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Good Practices" data-md-level="2">
        <label class="md-nav__title" for="__nav_5_8">
          <span class="md-nav__icon md-icon"></span>
          Good Practices
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../data_science_tools/github_good_practices/" class="md-nav__link">
        Github
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../data_science_tools/python_good_practices/" class="md-nav__link">
        Python
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_6" type="checkbox" id="__nav_6" >
      
      
      
      
        <label class="md-nav__link" for="__nav_6">
          Machine Learning
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Machine Learning" data-md-level="1">
        <label class="md-nav__title" for="__nav_6">
          <span class="md-nav__icon md-icon"></span>
          Machine Learning
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../machine_learning/introduction/" class="md-nav__link">
        Introduction
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../machine_learning/ML_snippets/" class="md-nav__link">
        ML snippets
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../machine_learning/interview_questions/" class="md-nav__link">
        Interview Questions
      </a>
    </li>
  

            
          
            
              
  
  
  
    
      
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_6_4" type="checkbox" id="__nav_6_4" >
      
      
      
      
        <label class="md-nav__link" for="__nav_6_4">
          Techniques
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Techniques" data-md-level="2">
        <label class="md-nav__title" for="__nav_6_4">
          <span class="md-nav__icon md-icon"></span>
          Techniques
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../machine_learning/clustering/" class="md-nav__link">
        Clustering
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../machine_learning/classification/" class="md-nav__link">
        Classification
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../machine_learning/loss_functions/" class="md-nav__link">
        Loss functions
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../machine_learning/genaidetection/" class="md-nav__link">
        Detecting AI Generated Content
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../machine_learning/dpo/" class="md-nav__link">
        Direct Preference Optimization (DPO)
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
      
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_6_5" type="checkbox" id="__nav_6_5" >
      
      
      
      
        <label class="md-nav__link" for="__nav_6_5">
          Model Compression
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Model Compression" data-md-level="2">
        <label class="md-nav__title" for="__nav_6_5">
          <span class="md-nav__icon md-icon"></span>
          Model Compression
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../machine_learning/model_compression_intro/" class="md-nav__link">
        Introduction
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../machine_learning/model_compression_kd/" class="md-nav__link">
        Knowledge Distillation
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../machine_learning/model_compression_quant/" class="md-nav__link">
        Model Quantization
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
      
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_6_6" type="checkbox" id="__nav_6_6" >
      
      
      
      
        <label class="md-nav__link" for="__nav_6_6">
          Optimization
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Optimization" data-md-level="2">
        <label class="md-nav__title" for="__nav_6_6">
          <span class="md-nav__icon md-icon"></span>
          Optimization
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../machine_learning/ranking_algorithms/" class="md-nav__link">
        Ranking Algorithms
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_7" type="checkbox" id="__nav_7" >
      
      
      
      
        <label class="md-nav__link" for="__nav_7">
          Reinforcement Learning
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Reinforcement Learning" data-md-level="1">
        <label class="md-nav__title" for="__nav_7">
          <span class="md-nav__icon md-icon"></span>
          Reinforcement Learning
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../reinforcement_learning/introduction/" class="md-nav__link">
        Introduction
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../reinforcement_learning/interview_questions/" class="md-nav__link">
        Interview Questions
      </a>
    </li>
  

            
          
            
              
  
  
  
    
      
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_7_3" type="checkbox" id="__nav_7_3" >
      
      
      
      
        <label class="md-nav__link" for="__nav_7_3">
          Techniques
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Techniques" data-md-level="2">
        <label class="md-nav__title" for="__nav_7_3">
          <span class="md-nav__icon md-icon"></span>
          Techniques
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../reinforcement_learning/rlhf/" class="md-nav__link">
        RLHF
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../reinforcement_learning/q_learning/" class="md-nav__link">
        Q-Learning
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../reinforcement_learning/multi_arm_bandit/" class="md-nav__link">
        Multi-Arm Bandit
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#introduction" class="md-nav__link">
    Introduction
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#traditional-audio-codecs" class="md-nav__link">
    Traditional Audio Codecs
  </a>
  
    <nav class="md-nav" aria-label="Traditional Audio Codecs">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#waveform-codecs" class="md-nav__link">
    Waveform Codecs
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#parametric-codecs" class="md-nav__link">
    Parametric Codecs
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#neural-audio-codecs_1" class="md-nav__link">
    Neural Audio Codecs
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#soundstream-end-to-end-neural-audio-coding" class="md-nav__link">
    SoundStream: End-to-End Neural Audio Coding
  </a>
  
    <nav class="md-nav" aria-label="SoundStream: End-to-End Neural Audio Coding">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#key-innovations" class="md-nav__link">
    Key Innovations
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#architectural-design" class="md-nav__link">
    Architectural Design
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#training-methodology" class="md-nav__link">
    Training Methodology
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#results" class="md-nav__link">
    Results
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#encodec-high-fidelity-neural-compression" class="md-nav__link">
    EnCodec: High-Fidelity Neural Compression
  </a>
  
    <nav class="md-nav" aria-label="EnCodec: High-Fidelity Neural Compression">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#key-innovations_1" class="md-nav__link">
    Key Innovations
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#results_1" class="md-nav__link">
    Results
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#hilcodec-lightweight-and-efficient-streaming" class="md-nav__link">
    HILCodec: Lightweight and Efficient Streaming
  </a>
  
    <nav class="md-nav" aria-label="HILCodec: Lightweight and Efficient Streaming">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#key-innovations_2" class="md-nav__link">
    Key Innovations
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#results_2" class="md-nav__link">
    Results
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#snac-multi-scale-neural-audio-codec" class="md-nav__link">
    SNAC: Multi-Scale Neural Audio Codec
  </a>
  
    <nav class="md-nav" aria-label="SNAC: Multi-Scale Neural Audio Codec">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#key-innovations_3" class="md-nav__link">
    Key Innovations
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#architectural-design_1" class="md-nav__link">
    Architectural Design
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#results_3" class="md-nav__link">
    Results
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#code" class="md-nav__link">
    Code
  </a>
  
    <nav class="md-nav" aria-label="Code">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#load-the-encodec-model-and-processor" class="md-nav__link">
    Load the EnCodec Model and Processor
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#loading-the-audio" class="md-nav__link">
    Loading the Audio
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#preprocessing-the-audio" class="md-nav__link">
    Preprocessing the Audio
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#encoding-the-audio" class="md-nav__link">
    Encoding the Audio
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#decoding-the-audio" class="md-nav__link">
    Decoding the Audio
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#comparative-analysis" class="md-nav__link">
    Comparative Analysis
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#challenges-and-future-directions" class="md-nav__link">
    Challenges and Future Directions
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#conclusion" class="md-nav__link">
    Conclusion
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#references" class="md-nav__link">
    References
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content" data-md-component="content">
            <article class="md-content__inner md-typeset">
              
                
  <a href="https://github.com/imohitmayank/a_lazy_data_science_guide/edit/master/docs/audio_intelligence/neural_audio_codecs.md" title="Edit this page" class="md-content__button md-icon">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20.71 7.04c.39-.39.39-1.04 0-1.41l-2.34-2.34c-.37-.39-1.02-.39-1.41 0l-1.84 1.83 3.75 3.75M3 17.25V21h3.75L17.81 9.93l-3.75-3.75L3 17.25Z"/></svg>
  </a>



<h1 id="neural-audio-codecs">Neural Audio Codecs</h1>
<h2 id="introduction">Introduction</h2>
<p>Neural audio codecs are a new generation of audio compression tools powered by deep learning. Unlike traditional codecs, which rely on hand-crafted signal processing, neural codecs learn to compress and reconstruct audio directly from data, achieving much higher quality at lower bitrates. In this guide, weâll explore three leading neural audio codecsâSoundStream, EnCodec, and HILCodecâhighlighting what makes each unique. Youâll also find practical code examples showing how to use neural audio codecs to compress and reconstruct audio, so you can experience their capabilities firsthand.</p>
<h2 id="traditional-audio-codecs">Traditional Audio Codecs</h2>
<p>Traditional audio codecs rely on signal processing techniques rooted in psychoacoustic models, which discard imperceptible audio components to reduce file sizes. Traditional audio codecs fall into two main camps, </p>
<h3 id="waveform-codecs">Waveform Codecs</h3>
<ul>
<li><strong>Goal:</strong> Reproduce the original audio as closely as possible, sample by sample.</li>
<li><strong>How They Work:</strong> <ul>
<li>They take the audio signal (which is a waveform in the time domain) and convert it into another form, usually the time-frequency domain, using a mathematical process called a <em>transform</em>.</li>
<li>After transformation, they compress the data by quantizing (rounding off) the numbers and encoding them efficiently.</li>
<li>When you want to listen to the audio, the codec reverses the process to get back to the time-domain waveform.</li>
</ul>
</li>
<li><strong>Features:</strong><ul>
<li>They don't make many assumptions about what kind of audio they're compressing, so they work for all types of soundsâmusic, speech, noise, etc.</li>
<li>They sound great at medium to high bitrates (more data per second), but at low bitrates (less data), you might hear strange artifacts or loss of quality.</li>
</ul>
</li>
<li><strong>Examples:</strong> MP3, Opus, AAC.</li>
</ul>
<h3 id="parametric-codecs">Parametric Codecs</h3>
<ul>
<li><strong>Goal:</strong> Reproduce audio that <em>sounds</em> like the original, even if it's not identical sample by sample.</li>
<li><strong>How They Work:</strong><ul>
<li>They assume the audio is of a specific type (usually speech).</li>
<li>Instead of saving the whole waveform, they analyze the audio and extract important features or parameters (like pitch, tone, speed).</li>
<li>Only these parameters are compressed and sent.</li>
<li>The decoder then uses a model to <em>synthesize</em> (recreate) the audio using the parameters.</li>
</ul>
</li>
<li><strong>Features:</strong><ul>
<li>They are very efficient at low bitrates and can produce understandable speech with very little data.</li>
<li>They don't try to perfectly recreate every detail, just make the audio sound similar to the original to our ears.</li>
<li>They usually work best for speech and may not be suitable for music or complex sounds.</li>
</ul>
</li>
<li><strong>Examples:</strong> Some VoIP codecs, like EVS or MELP.</li>
</ul>
<p>Both approaches rely on hand-crafted signal processing pipelines, which limit their flexibility and performanceâespecially as we demand better quality at lower bitrates, and for more diverse content (music, ambient sounds, etc.).</p>
<div class="admonition info">
<p class="admonition-title">Did you know?</p>
<p>The Opus codec, standardized in 2012, is the audio engine behind popular apps like Zoom, Microsoft Teams, Google Meet, and even YouTube streaming! Its widespread adoption means that hundreds of millions of people use Opus every dayâoften without even realizing it. Meanwhile, the Enhanced Voice Services (EVS) codec, designed for Voice over LTE (VoLTE), is taking over as the new standard for mobile calls, offering improved quality and full compatibility with older systems.</p>
</div>
<h2 id="neural-audio-codecs_1">Neural Audio Codecs</h2>
<p>Neural audio codecs use deep learning to learn efficient, perceptually meaningful representations of audio directly from data. This opens the door to higher quality, lower bitrates, and new features like joint enhancement and compression. These systems typically consist of three components:  </p>
<ol>
<li>
<p>An <strong>encoder</strong> that converts raw audio into a compressed latent representation.  </p>
</li>
<li>
<p>A <strong>quantizer</strong> that maps continuous latent vectors to discrete symbols for efficient storage/transmission.  </p>
</li>
<li>
<p>A <strong>decoder</strong> that reconstructs audio from the quantized representation.  </p>
</li>
</ol>
<figure>
<p><img alt="" src="../../imgs/audio_nc_soundstream_neural_audio_codec.png" />
    <figcaption> Neural Audio Codecs Architecture</figcaption></p>
</figure>
<p>The key advantage lies in their end-to-end training process, where all components are optimized jointly to minimize perceptual differences between original and reconstructed audio. This data-driven approach allows neural codecs to adapt to complex audio patterns that challenge rule-based systems, particularly at ultra-low bitrates (&lt;6 kbps).  </p>
<h2 id="soundstream-end-to-end-neural-audio-coding">SoundStream: End-to-End Neural Audio Coding</h2>
<p>SoundStream is a fully end-to-end neural audio codec that can compress speech, music, and general audio at bitrates as low as 3 kbpsâoutperforming traditional codecs at much higher bitrates.</p>
<h3 id="key-innovations">Key Innovations</h3>
<ul>
<li><strong>End-to-End Training:</strong> The entire pipelineâencoder, quantizer, and decoderâis trained jointly, optimizing for both reconstruction accuracy and perceptual quality via adversarial losses.</li>
</ul>
<ul>
<li><strong>Residual Vector Quantization (RVQ):</strong> Instead of a single quantization step, SoundStream uses a multi-stage (residual) vector quantizer. This allows it to represent audio more efficiently and enables bitrate scalability.</li>
</ul>
<ul>
<li><strong>Bitrate Scalability:</strong> Thanks to a novel "quantizer dropout" during training, a single SoundStream model can operate at different bitrates (3â18 kbps) with minimal quality loss.</li>
</ul>
<ul>
<li><strong>Low Latency &amp; Real-Time:</strong> The model is fully convolutional and causal, making it suitable for low-latency, real-time applicationsâeven on a smartphone CPU.</li>
</ul>
<ul>
<li><strong>Joint Compression and Enhancement:</strong> SoundStream can simultaneously compress and enhance audio (e.g., denoise speech) with no extra latency.</li>
</ul>
<figure>
<p><img alt="" src="../../imgs/audio_nc_soundstream_architecture.png" />
    <figcaption>SoundStream Architecture. Source: [1]</figcaption></p>
</figure>
<h3 id="architectural-design">Architectural Design</h3>
<p>The system uses a fully convolutional U-Net structure with strided convolutions for downsampling and transposed convolutions for upsampling. A residual vector quantizer (RVQ) between encoder and decoder discretizes the latent space while maintaining reconstruction fidelity. Crucially, SoundStream introduced structured dropout during training, enabling a single model to operate across multiple bitrates (3-18 kbps) without quality degradation.  </p>
<figure>
<p><img alt="" src="../../imgs/audio_nc_soundstream_encoderdecoder.png" />
    <figcaption>SoundStream Encoder-Decoder Architecture. Source: [1]</figcaption></p>
</figure>
<h3 id="training-methodology">Training Methodology</h3>
<p>SoundStream combines adversarial training with multi-resolution spectral losses:  </p>
<ul>
<li>A <strong>GAN discriminator</strong> distinguishes real/fake audio samples, forcing the decoder to generate perceptually convincing outputs.  </li>
</ul>
<ul>
<li><strong>Multi-scale spectrogram losses</strong> ensure accurate frequency domain reconstruction.  </li>
</ul>
<ul>
<li><strong>Feature matching losses</strong> align intermediate layer activations between original and reconstructed audio.  </li>
</ul>
<figure>
<p><img alt="" src="../../imgs/audio_nc_soundstream_discriminator.png" width="500" />
    <figcaption>SoundStream Discriminator Architecture. Source: [1]</figcaption></p>
</figure>
<h3 id="results">Results</h3>
<p>The results are impressive:</p>
<ul>
<li>At 3 kbps, SoundStream outperforms Opus at 12 kbps and approaches the quality of EVS at 9.6 kbps.</li>
</ul>
<ul>
<li>It works for speech, music, and general audioânot just speech.</li>
</ul>
<ul>
<li>Subjective tests (MUSHRA) show that listeners prefer SoundStream's output at low bitrates over traditional codecs.</li>
</ul>
<figure>
<p><img alt="" src="../../imgs/audio_nc_soundstream_results.png" />
    <figcaption>SoundStream Performance Results. Source: [1]</figcaption></p>
</figure>
<h2 id="encodec-high-fidelity-neural-compression">EnCodec: High-Fidelity Neural Compression</h2>
<p>Meta's EnCodec (2022) builds on SoundStream's foundation while addressing scalability and stability challenges. </p>
<figure>
<p><img alt="" src="../../imgs/audio_nc_encodec_architecture.png" />
    <figcaption>EnCodec Architecture. Source: [2]</figcaption></p>
</figure>
<h3 id="key-innovations_1">Key Innovations</h3>
<ul>
<li>
<p><strong>Spectrogram Adversary</strong>: EnCodec replaces SoundStream's waveform discriminator with a <strong>multi-scale spectrogram discriminator</strong>, which analyzes audio at different time-frequency resolutions. This modification:  </p>
<ul>
<li>Reduces artifacts caused by phase inconsistencies in waveform-based GANs  </li>
</ul>
<ul>
<li>Improves training stability through better gradient signals  </li>
</ul>
<ul>
<li>
<p>Enables effective handling of stereo audio at 48 kHz sampling rates</p>
<p><figure markdown> 
    <img alt="" src="../../imgs/audio_nc_encodec_discriminator.png" />
    <figcaption>EnCodec's Multi-scale Spectrogram Discriminator. Source: [2]</figcaption>
</figure></p>
</li>
</ul>
</li>
</ul>
<ul>
<li><strong>Loss Balancing Mechanism</strong>: The authors introduced a <strong>gradient-balancing</strong> technique that dynamically adjusts loss weights based on their contribution to the total gradient magnitude. This innovation decouples hyperparameter tuning from loss function scales, significantly simplifying training.  </li>
</ul>
<ul>
<li><strong>Latent Space Compression</strong>: EnCodec demonstrates how lightweight Transformer models can further compress the quantized latent representation by 40%, enabling variable-rate compression without retraining. Subjective evaluations show EnCodec outperforming EVS at 16.4 kbps while operating at 9 kbps, with particularly strong performance on music and noisy speech.  </li>
</ul>
<h3 id="results_1">Results</h3>
<p>EnCodec was rigorously evaluated across a range of bitrates and content types (speech, music, noisy and reverberant speech). Key findings include:</p>
<ul>
<li><strong>Superior Quality:</strong> At all tested bitrates (1.5, 3, 6, 12 kbps for 24 kHz; 6, 12, 24 kbps for 48 kHz), EnCodec outperformed traditional codecs and previous neural models in both objective and subjective (MUSHRA) tests.</li>
</ul>
<ul>
<li><strong>Versatility:</strong> Works seamlessly for both speech and music, and robustly handles challenging conditions like noise and reverberation.</li>
</ul>
<ul>
<li><strong>Efficiency:</strong> Achieves real-time encoding and decoding on a single CPU core, making it practical for large-scale deployment.</li>
</ul>
<figure>
<p><img alt="" src="../../imgs/audio_nc_encodec_results.png" />
    <figcaption>EnCodec Performance Results. Source: [2]</figcaption></p>
</figure>
<h2 id="hilcodec-lightweight-and-efficient-streaming">HILCodec: Lightweight and Efficient Streaming</h2>
<p>The 2024 HILCodec paper addresses critical limitations in prior neural codecsâmodel complexity and streaming efficiency [3].</p>
<figure>
<p><img alt="" src="../../imgs/audio_nc_hilcodec_architecture.png" />
    <figcaption>HILCodec Architecture. Source: [3]</figcaption></p>
</figure>
<h3 id="key-innovations_2">Key Innovations</h3>
<ul>
<li>
<p><strong>Variance-Constrained Wave-U-Net</strong> Through theoretical analysis, the authors identified that standard Wave-U-Net architectures suffer from <strong>exponential variance growth</strong> in deeper layers, leading to unstable training and performance degradation. HILCodec introduces:  </p>
<ul>
<li><strong>L2-normalization</strong> after each residual block to control activation scales  </li>
</ul>
<ul>
<li><strong>Depthwise separable convolutions</strong> to maintain receptive field while reducing parameters  </li>
</ul>
<ul>
<li><strong>Causal convolutions</strong> with 20ms latency for real-time streaming </li>
</ul>
</li>
</ul>
<ul>
<li><strong>Distortion-Free Discriminator</strong> Traditional waveform discriminators introduce spectral distortions by prioritizing time-domain accuracy. HILCodec's discriminator uses <strong>parallel filter banks</strong> analyzing different frequency bands, ensuring artifact-free reconstructions across the audible spectrum.  <p><figure markdown> 
      <img alt="" src="../../imgs/audio_nc_hilcodec_discriminator.png" />
      <figcaption>HILCodec's Distortion-Free Discriminator. Source: [3]</figcaption>
  </figure></p>
</li>
</ul>
<h3 id="results_2">Results</h3>
<p>HILCodec matches or outperforms both traditional and leading neural codecs (like SoundStream, EnCodec, and HiFi-Codec) in subjective and objective tests, across various audio types (speech, music, environmental sounds) and bitrates (1.5â9 kbps). It achieves this with:</p>
<ul>
<li><strong>Lower computational complexity</strong>: Real-time on a single CPU thread</li>
</ul>
<ul>
<li><strong>Superior or comparable perceptual quality</strong>: Especially at very low bitrates</li>
</ul>
<ul>
<li><strong>Streamable design</strong>: Suitable for live audio and embedded applications</li>
</ul>
<figure>
<p><img alt="" src="../../imgs/audio_nc_hilcodec_results.png" />
    <figcaption>HILCodec Performance Results. Source: [3]</figcaption></p>
</figure>
<h2 id="snac-multi-scale-neural-audio-codec">SNAC: Multi-Scale Neural Audio Codec</h2>
<p>SNAC (Multi-Scale Neural Audio Codec), introduced in 2024, extends the Residual Vector Quantization (RVQ) framework by introducing quantization at different temporal resolutions, enabling more efficient compression through multi-scale discrete audio representations [4].</p>
<figure>
<p><img alt="" src="../../imgs/audio_nc_snac_architecture.png" />
    <figcaption>RVQ Multi-Scale Quantization. Source: [4]</figcaption></p>
</figure>
<h3 id="key-innovations_3">Key Innovations</h3>
<ul>
<li>
<p><strong>Multi-Scale Residual Vector Quantization</strong>: Unlike traditional RVQ approaches that operate at a fixed temporal resolution, SNAC employs a hierarchy of quantizers operating at multiple temporal resolutions. At each quantization iteration, the residuals are downsampled by a factor <span class="arithmatex">\(W_i\)</span>, quantized, and then upsampled back to match the original temporal resolution. This multi-scale approach allows the codec to capture both coarse and fine audio details more efficiently:</p>
<ul>
<li>Coarse temporal structure (like prosody and semantic patterns) is captured at lower frame rates</li>
<li>Fine acoustic details are preserved at higher frame rates</li>
<li>This hierarchical organization aligns with how human auditory cortex processes acoustic signals</li>
</ul>
</li>
</ul>
<ul>
<li>
<p><strong>Noise Block</strong>: After each upsampling layer, SNAC introduces a Noise Block that adds input-dependent stochasticity. The block updates activations as: </p>
<div class="arithmatex">\[
\mathbf{x} \leftarrow \mathbf{x} + \text{Linear}(\mathbf{x}) \odot {\epsilon}, \text{where } \epsilon \sim \mathcal{N}(0,1) \text{ is Gaussian noise.}
\]</div>
<p>This mechanism enhances decoder expressiveness, improves reconstruction quality, and leads to better codebook utilization.</p>
</li>
</ul>
<ul>
<li><strong>Depthwise Convolution</strong>: SNAC incorporates depthwise separable convolutions in the generator to reduce parameters and stabilize training. This is particularly beneficial for GAN-based vocoders, which are notoriously unstable during training.</li>
</ul>
<ul>
<li><strong>Local Windowed Attention</strong>: The model uses local windowed attention mechanisms, enabling efficient processing of longer audio sequences while maintaining computational efficiency.</li>
</ul>
<h3 id="architectural-design_1">Architectural Design</h3>
<p>SNAC builds upon the RVQGAN framework, maintaining the encoder-decoder structure with a cascade of vector quantization layers. The key difference lies in the multi-scale quantization strategy: instead of quantizing all residuals at the same temporal resolution, SNAC applies a hierarchy of quantizers with variable frame rates. Average pooling is used for downsampling, while nearest-neighbor interpolation handles upsampling to restore the original temporal resolution.</p>
<h3 id="results_3">Results</h3>
<p>SNAC demonstrates superior compression efficiency compared to existing neural audio codecs:</p>
<p><strong>Speech Performance:</strong></p>
<ul>
<li>At 0.98 kbps, SNAC achieves a MUSHRA score of <span class="arithmatex">\(88.4 \pm 2.6\)</span>, outperforming EnCodec at 1.5 kbps (<span class="arithmatex">\(39.1 \pm 3.0\)</span>) and DAC at 0.8 kbps (<span class="arithmatex">\(33.0 \pm 4.4\)</span>)</li>
<li>Achieves competitive ViSQOL (4.14) and SI-SDR (0.82) scores even at ultra-low bitrates</li>
<li>Lower Mel-spectrogram and STFT reconstruction errors compared to EnCodec at similar bitrates</li>
</ul>
<p><strong>Music Performance:</strong></p>
<ul>
<li>At 1.9 kbps, achieves MUSHRA score of <span class="arithmatex">\(77.9 \pm 4.3\)</span>, competitive with DAC at 2.5 kbps (<span class="arithmatex">\(54.0 \pm 6.0\)</span>)</li>
<li>At 2.6 kbps, achieves MUSHRA score of <span class="arithmatex">\(76.8 \pm 4.6\)</span> with ViSQOL of 4.04 and SI-SDR of 5.17</li>
<li>Demonstrates effective handling of musical structures across multiple timescales</li>
</ul>
<p>The multi-scale approach enables SNAC to achieve better quality at lower bitrates by adapting to audio structure across multiple temporal resolutions, making it particularly effective for capturing both local acoustic details and long-term patterns in speech and music.</p>
<figure>
<p><img alt="" src="../../imgs/audio_nc_snac_results.png" />
    <figcaption>SNAC Performance Results. Source: [4]</figcaption></p>
</figure>
<h2 id="code">Code</h2>
<p>Let's walk through a hands-on example to see how to use one of these neural audio codecs in practice. Here, we will use EnCodec [2], but the fundamental steps are similar for other codecs like SoundStream or HILCodec.</p>
<p><div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 1</span>
<span class="normal"> 2</span>
<span class="normal"> 3</span>
<span class="normal"> 4</span>
<span class="normal"> 5</span>
<span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="c1"># Load the required packages</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">audiotools</span><span class="w"> </span><span class="kn">import</span> <span class="n">AudioSignal</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">EncodecModel</span><span class="p">,</span> <span class="n">AutoProcessor</span>

<span class="c1"># Step 1: load the EnCodec model and processor</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">EncodecModel</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;facebook/encodec_24khz&quot;</span><span class="p">)</span>
<span class="n">processor</span> <span class="o">=</span> <span class="n">AutoProcessor</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;facebook/encodec_24khz&quot;</span><span class="p">)</span>
<span class="c1"># Note: you can also use &quot;facebook/encodec_48khz&quot; for higher sampling rates</span>

<span class="c1"># Step 2: load an audio file</span>
<span class="n">audio_file</span> <span class="o">=</span> <span class="s2">&quot;samples/neural_codec_input.wav&quot;</span> <span class="c1"># replace with your audio file path</span>
<span class="n">audio</span> <span class="o">=</span> <span class="n">AudioSignal</span><span class="p">(</span><span class="n">audio_file</span><span class="p">)</span>
<span class="n">audio</span> <span class="o">=</span> <span class="n">audio</span><span class="o">.</span><span class="n">resample</span><span class="p">(</span><span class="mi">24000</span><span class="p">)</span> <span class="c1"># resample to 24kHz</span>
<span class="n">audio</span> <span class="o">=</span> <span class="n">audio</span><span class="o">.</span><span class="n">to_mono</span><span class="p">()</span> <span class="c1"># convert to mono</span>
<span class="n">frame_rate</span> <span class="o">=</span> <span class="n">audio</span><span class="o">.</span><span class="n">sample_rate</span> <span class="c1"># get the sample rate</span>
<span class="n">audio_sample</span> <span class="o">=</span> <span class="n">audio</span><span class="o">.</span><span class="n">audio_data</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># get the reshaped audio samples</span>

<span class="c1"># Step 3: Preprocess the audio</span>
<span class="n">inputs</span> <span class="o">=</span> <span class="n">processor</span><span class="p">(</span><span class="n">raw_audio</span><span class="o">=</span><span class="n">audio_sample</span><span class="p">,</span> 
                    <span class="n">sampling_rate</span><span class="o">=</span><span class="n">frame_rate</span><span class="p">,</span> 
                    <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span>

<span class="c1"># Step 4: Encode the audio</span>
<span class="n">encoder_outputs</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">inputs</span><span class="p">[</span><span class="s2">&quot;input_values&quot;</span><span class="p">],</span> 
                                <span class="n">inputs</span><span class="p">[</span><span class="s2">&quot;padding_mask&quot;</span><span class="p">])</span>

<span class="c1"># Step 5: Decode the audio</span>
<span class="n">audio_values</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">encoder_outputs</span><span class="o">.</span><span class="n">audio_codes</span><span class="p">,</span> 
                            <span class="n">encoder_outputs</span><span class="o">.</span><span class="n">audio_scales</span><span class="p">,</span> 
                            <span class="n">inputs</span><span class="p">[</span><span class="s2">&quot;padding_mask&quot;</span><span class="p">])[</span><span class="mi">0</span><span class="p">]</span>

<span class="c1"># OR replace Step 4 and 5: Forward pass on the input</span>
<span class="n">audio_values</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">inputs</span><span class="p">[</span><span class="s2">&quot;input_values&quot;</span><span class="p">],</span> <span class="n">inputs</span><span class="p">[</span><span class="s2">&quot;padding_mask&quot;</span><span class="p">])</span><span class="o">.</span><span class="n">audio_values</span> 
</code></pre></div></td></tr></table></div>
Let's go through the important code steps:</p>
<h3 id="load-the-encodec-model-and-processor">Load the EnCodec Model and Processor</h3>
<p>We use the <code>facebook/encodec_24khz</code> model, optimized for 24 kHz audio. The processor handles audio preprocessing, including splitting audio for batch operations and creating the <code>padding_mask</code>, that indicates which positions in the input are real audio (1) and which are padding (0) to be ignored by the model. </p>
<div class="admonition hint">
<p class="admonition-title">Hint</p>
<p>You can also use <code>facebook/encodec_48khz</code> for higher sampling rates, but in this example, we will stick to 24 kHz for simplicity.</p>
</div>
<h3 id="loading-the-audio">Loading the Audio</h3>
<p>We load an audio file, resample it to 24 kHz, and convert it to mono. The audio data is reshaped into a 1D array for processing. In this example, we use a sample audio file named <code>neural_codec_input.wav</code> <em>(listen to it below)</em> that is 10 seconds long and after resampling, has the shape of <code>torch.Size([240000])</code> and looks like <code>tensor([0.0088, 0.0117, 0.0194,  ..., 0.0390, 0.0460, 0.0213])</code></p>
<p>Original Audio:
<audio controls>
  <source src="../../audio/neural_codec_input.wav" type="audio/wav">
Your browser does not support the audio element.
</audio></p>
<h3 id="preprocessing-the-audio">Preprocessing the Audio</h3>
<p>The audio is processed using the EnCodec processor, which prepares it for encoding by creating input tensors and a padding mask. The padding mask is crucial for handling variable-length audio inputs, ensuring that the model only processes valid audio samples. The <code>inputs</code> looks like <code>{'input_values': tensor([[ 0.0088,  0.0117,  0.0194,  ...,  0.0390,  0.0460,  0.0213]]), 'padding_mask': tensor([[1, 1, 1, ..., 1, 1, 1]])}</code>. If you notice, the <code>input_values</code> tensor contains the audio samples exactly as we have loaded, and the <code>padding_mask</code> indicates that all positions are valid (1) since we have a single audio sample without padding.</p>
<h3 id="encoding-the-audio">Encoding the Audio</h3>
<p>The <code>encode</code> method processes the input audio, producing quantized latent representations (<code>audio_codes</code>) and scales for decoding. This step compresses the audio into a more compact form. One important aspect here is the bandwidth -  this is how much data the compressed audio will use per second. Lower bandwidth means smaller files but lower audio quality; higher bandwidth means better quality but larger files. Bandwidth is correlated to the codebooks used in the quantization step, the relation is shown below, <em>(for Encodec 24kHz model)</em>:</p>
<table>
<thead>
<tr>
<th>Bandwidth (kbps)</th>
<th>Number of Codebooks (n_q)</th>
</tr>
</thead>
<tbody>
<tr>
<td>1.5</td>
<td>2</td>
</tr>
<tr>
<td>3</td>
<td>4</td>
</tr>
<tr>
<td>6</td>
<td>8</td>
</tr>
<tr>
<td>12</td>
<td>16</td>
</tr>
<tr>
<td>24</td>
<td>32</td>
</tr>
</tbody>
</table>
<p>So, <code>bandwidth = 1.5</code> will use 2 codebooks, while <code>bandwidth = 24</code> will use 32 codebooks. The number of codebooks directly affects the quality and size of the compressed audio. If we try with <code>bandwidth = 1.5</code>, the <code>audio_codes</code> will have shape <code>torch.Size([1, 1, 2, 750])</code> and looks like </p>
<div class="highlight"><pre><span></span><code>tensor([[[[727, 407, 906,  ..., 561, 424, 925],
        [946, 734, 949,  ..., 673, 769, 987]]]])
</code></pre></div>
<p>But in case of <code>bandwidth = 24</code>, the <code>audio_codes</code> will have shape <code>torch.Size([1, 1, 32, 750])</code> and looks like </p>
<div class="highlight"><pre><span></span><code>tensor([[[[ 727,  407,  906,  ...,  561,  424,  925],
        [ 946,  734,  949,  ...,  673,  769,  987],
        [ 988,   21,  623,  ...,  870, 1023,  452],
        ...,
        [ 792,  792,  220,  ...,  419, 1011,  422],
        [ 502,  550,  893,  ...,  328,  832,  450],
        [ 681,  906,  872,  ...,  820,  601,  658]]]])
</code></pre></div>
<div class="admonition hint">
<p class="admonition-title">Hint</p>
<p>If you're wondering how bandwidth relates to the number of codebooks in EnCodec, here's how it works: </p>
<p>The encoder produces 75 steps per second of audio (i.e. 750 steps for a 10-second clip) per codebook (<code>N_q</code>). For example, with <code>bandwidth = 1.5</code>, there are 2 codebooks, so you get a total of 2 Ã 75 = 150 codes per second. Now, in EnCodec, each codebook has 1024 unique entries which can be represented by 10bit id (as <span class="arithmatex">\(log_2(1024) = 10\)</span>). So, the total number of bits per second is 150 (steps) * 10 (id) = 1500 bits/s which corresponds to 1.5 kbps. 
Similarly, with <code>bandwidth = 24</code>, there are 32 codebooks, resulting in 32 Ã 75 = 2400 codes, or 2400*10 = 24000 bits/s which corresponds to 24 kbps.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>SNAC uses a similar approach, but with a multi-scale quantization strategy, where the quantization is done at different temporal resolutions which results in token rates of 12Hz, ~24Hz and ~48Hz. This means the shape of the quantized audio (24 kHz Speech model) follows the shape of (12 * seconds, 24 * seconds, 48 * seconds). Example: for a 10 second audio, the shape will be ~(120, 240, 480). </p>
</div>
<p>Notice one thing, an audio of 10 seconds that used 240k samples is now compressed into (N_q, 750) where N_q is the number of codebooks used. For <code>bandwidth = 1.5</code>, the shape is (2, 750) and the compression ratio is 160x and for <code>bandwidth = 24</code>, the shape is (32, 750) and the compression ratio is 10x! Quite impressive, right?</p>
<h3 id="decoding-the-audio">Decoding the Audio</h3>
<p>The <code>decode</code> method reconstructs the audio from the quantized codes and scales. The output is a tensor of audio samples, which can be saved as a WAV file or played directly. The shape of the output audio tensor will be <code>(1, 240000)</code> for 10 seconds of audio at 24 kHz.</p>
<p>If you play the audio file <code>neural_codec_input.wav</code>, you will hear the original audio. After running the code, you can listen to the output generated by EnCodec. Both are presented below, </p>
<p>Original Audio: (48KHz)
<audio controls>
  <source src="../../audio/neural_codec_input.wav" type="audio/wav">
Your browser does not support the audio element.
</audio></p>
<p>Encodec Output: (24KHz; Bandwidth: 1.5 kbps)
<audio controls>
  <source src="../../audio/neural_codec_encodec_output_bandwidth1.5.wav" type="audio/wav">
Your browser does not support the audio element.
</audio></p>
<p>Encodec Output: (24KHz; Bandwidth: 24 kbps)
<audio controls>
  <source src="../../audio/neural_codec_encodec_output_bandwidth24.wav" type="audio/wav">
Your browser does not support the audio element.
</audio></p>
<p>As you can hear, while there are some distortions, the output is audible and is able to maintain the speech of the original audio.  This demonstrates the effectiveness of neural codecs in audio compression. </p>
<h2 id="comparative-analysis">Comparative Analysis</h2>
<p>The evolution of neural codecs reveals several key trends:  </p>
<table>
<thead>
<tr>
<th>Characteristic</th>
<th>SoundStream[1]</th>
<th>EnCodec[2]</th>
<th>HILCodec[3]</th>
<th>SNAC[4]</th>
</tr>
</thead>
<tbody>
<tr>
<td>Max Sampling Rate</td>
<td>24 kHz</td>
<td>48 kHz</td>
<td>24 kHz</td>
<td>44.1 kHz</td>
</tr>
<tr>
<td>Real-Time Streaming</td>
<td>Yes</td>
<td>Yes</td>
<td>Yes</td>
<td>Yes</td>
</tr>
<tr>
<td>Model Size (Params)</td>
<td>18M</td>
<td>32M</td>
<td>9M</td>
<td>54.5M</td>
</tr>
<tr>
<td>Music Handling</td>
<td>Moderate</td>
<td>Excellent</td>
<td>Excellent</td>
<td>Excellent</td>
</tr>
<tr>
<td>Quantization Scheme</td>
<td>RVQ (8-32 dim)</td>
<td>RVQ (32 dim)</td>
<td>RVQ (64 dim)</td>
<td>Multi-Scale RVQ</td>
</tr>
</tbody>
</table>
<h2 id="challenges-and-future-directions">Challenges and Future Directions</h2>
<p>While neural codecs demonstrate remarkable capabilities, several open challenges remain:  </p>
<ul>
<li><strong>Computational Complexity</strong>: Even lightweight models like HILCodec require 1-2 GFLOPS, posing deployment challenges on ultra-low-power devices.  </li>
</ul>
<ul>
<li><strong>Generalization</strong>: Most models are trained on specific audio types (speech/music), struggling with uncommon sounds like ultrasonic frequencies or simultaneous overlapping sources.  </li>
</ul>
<ul>
<li><strong>Standardization</strong>: Unlike traditional codecs with well-defined bitstream formats, neural codecs lack interoperability standards, hindering widespread adoption.  </li>
</ul>
<p>Emerging research directions include:  </p>
<ul>
<li><strong>Few-shot Adaptation</strong>: Allowing codecs to dynamically adjust to new speaker voices or musical instruments without retraining  </li>
</ul>
<ul>
<li><strong>Neural Post-Processing</strong>: Combining traditional codecs with neural enhancers for backward compatibility</li>
</ul>
<ul>
<li><strong>Energy-Efficient Architectures</strong>: Exploring sparsity and quantization-aware training for edge deployment  </li>
</ul>
<h2 id="conclusion">Conclusion</h2>
<p>Neural audio codecs represent a paradigm shift in audio compression, offering unprecedented quality/bitrate ratios through data-driven learning. From SoundStream's foundational architecture to HILCodec's efficient streaming design, and SNAC's multi-scale quantization approach, each iteration brings us closer to practical applications in telecommunication, media streaming, and immersive audio. As research addresses current limitations in complexity and generalization, these AI-powered codecs are poised to become the new standard for audio compression across industries.</p>
<h2 id="references">References</h2>
<p>[1] SoundStream: An End-to-End Neural Audio Codec - <a href="https://arxiv.org/abs/2107.03312">Paper</a> | <a href="https://www.youtube.com/watch?v=V4jj-yhiclk&amp;ab_channel=RISEResearchInstitutesofSweden">Video</a></p>
<p>[2] EnCodec: High Fidelity Neural Audio Compression - <a href="https://arxiv.org/abs/2210.13438">Paper</a> | <a href="https://github.com/facebookresearch/encodec">Code</a></p>
<p>[3] <a href="https://arxiv.org/pdf/2405.04752v1">HILCodec: High Fidelity and Lightweight Neural Audio Codec</a></p>
<p>[4] SNAC: Multi-Scale Neural Audio Codec - <a href="https://arxiv.org/pdf/2410.14411">Paper</a> | <a href="https://github.com/hubertsiuzdak/snac">Code</a></p>

              
            </article>
            
          </div>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
    
    <nav class="md-footer__inner md-grid" aria-label="Footer" >
      
        
        <a href="../tts/" class="md-footer__link md-footer__link--prev" aria-label="Previous: TTS Introduction" rel="prev">
          <div class="md-footer__button md-icon">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
          </div>
          <div class="md-footer__title">
            <div class="md-ellipsis">
              <span class="md-footer__direction">
                Previous
              </span>
              TTS Introduction
            </div>
          </div>
        </a>
      
      
        
        <a href="../training_tts/" class="md-footer__link md-footer__link--next" aria-label="Next: Training LLM-Based + Neural Codec TTS Models" rel="next">
          <div class="md-footer__title">
            <div class="md-ellipsis">
              <span class="md-footer__direction">
                Next
              </span>
              Training LLM-Based + Neural Codec TTS Models
            </div>
          </div>
          <div class="md-footer__button md-icon">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4Z"/></svg>
          </div>
        </a>
      
    </nav>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
        <div class="md-social">
  
    
    
      
      
    
    <a href="https://twitter.com/imohitmayank" target="_blank" rel="noopener" title="twitter.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.1.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"/></svg>
    </a>
  
    
    
      
      
    
    <a href="https://github.com/imohitmayank" target="_blank" rel="noopener" title="github.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.1.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>
    </a>
  
    
    
      
      
    
    <a href="https://www.linkedin.com/in/imohitmayank/" target="_blank" rel="noopener" title="www.linkedin.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.1.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"/></svg>
    </a>
  
    
    
      
      
    
    <a href="https://medium.com/@mohitmayank" target="_blank" rel="noopener" title="medium.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 640 512"><!--! Font Awesome Free 6.1.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M180.5 74.262C80.813 74.262 0 155.633 0 256s80.819 181.738 180.5 181.738S361 356.373 361 256 280.191 74.262 180.5 74.262Zm288.25 10.646c-49.845 0-90.245 76.619-90.245 171.095s40.406 171.1 90.251 171.1 90.251-76.619 90.251-171.1H559c0-94.503-40.4-171.095-90.248-171.095Zm139.506 17.821c-17.526 0-31.735 68.628-31.735 153.274s14.2 153.274 31.735 153.274S640 340.631 640 256c0-84.649-14.215-153.271-31.742-153.271Z"/></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    <script id="__config" type="application/json">{"base": "../..", "features": ["navigation.tabs", "navigation.sections"], "search": "../../assets/javascripts/workers/search.85cb4492.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.config.lang": "en", "search.config.pipeline": "trimmer, stopWordFilter", "search.config.separator": "[\\s\\-]+", "search.placeholder": "Search", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version.title": "Select version"}}</script>
    
    
      <script src="../../assets/javascripts/bundle.f758a944.min.js"></script>
      
        <script src="../../javascripts/mathjax.js"></script>
      
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      
    
  </body>
</html>